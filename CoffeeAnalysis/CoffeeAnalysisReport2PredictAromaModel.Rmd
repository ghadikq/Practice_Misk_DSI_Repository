---
title: "Coffee Analysis: Create Model to predict Coffee Aroma"
author: "Ghadi K"
date: "22-10-2020"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
    theme: paper
---

```{r setup, include=FALSE, echo=FALSE , warning=FALSE, message=FALSE}

knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE , warning=FALSE, message=FALSE}
# choce the colums i need & clean data 
library(tidyverse)
library(DT)
library(sjPlot)
library(sjmisc)
library(sjlabelled)

coffee_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')

TestCoffeeData <- coffee_ratings %>% 
  select(aroma,total_cup_points,flavor,acidity,sweetness,aftertaste)

```

# Data Introduction

talk about the data....

[source](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-07-07/readme.md)

What are the main research questions that you'll attempt to answer with this data?

# Descriptive Statistics

The mean and standard deviation of Aroma for each Country of origin.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
coffeeTable <- TestCoffeeData %>% 
  group_by(flavor) %>% 
  summarise(n = length(flavor),
            Average = mean(aroma),
            SD = sd(aroma))
datatable(coffeeTable)
```

Seeing the corelation between columns I chose from dataset. This helped me chose the variabels that I will use in my report.

```{r, echo=FALSE , warning=FALSE, message=FALSE}

corCoffee <- cor(TestCoffeeData, method = c("pearson", "kendall", "spearman"))
datatable(corCoffee)

```

# Data Visualization


## Scatter Plot 


```{r, echo=FALSE , warning=FALSE, message=FALSE}
FAP <- ggplot(TestCoffeeData, aes(x = flavor, y = aroma)) 
posn_j <- position_jitter(seed = 136)

FAP +
  geom_jitter(position = posn_j, shape = 1) +
  geom_smooth(method = "lm", se = FALSE, color = "#a6611a") +
  scale_color_brewer("", palette = "Dark2") +
  coord_cartesian(xlim = c(0,9), ylim = c(0,9), expand = 0, clip = "off") +
  labs(title = "The Flavor Aroma Plot", 
       caption = "Represent data points", 
       x = "Flavor (grade)",
       y = "Arome (grade)",
       color = "") +
  theme_classic(10) +
  theme(aspect.ratio = 1,
        axis.line = element_blank())
```



# Linear Regression Model
## Flavor - Aroma
Fit the data into Linear Regression Model (Train - Test).
```{r, echo=FALSE , warning=FALSE, message=FALSE}
# Fitting a model 
set.seed(136)
gp <- runif(nrow(TestCoffeeData))
dtrain <- subset(TestCoffeeData , gp >= 0.3)
dtest <- subset(TestCoffeeData , gp < 0.3)

model1 <- lm( aroma ~ flavor, data = dtrain)

  dtestP <- predict(model1, newdata = dtest)
  dtrainP <- predict(model1, newdata = dtrain)

```

```{r, echo=FALSE , warning=FALSE, message=FALSE}
# computing R-squared 
rsq <- function(y , f) { 1 - sum((y - f)^2) / sum((y - mean(y))^2 ) }
#rsq <- function (x, y) cor(x, y) ^ 2
rsq(dtest$aroma,dtestP)
rsq(dtrain$aroma,dtrainP)
```

```{r, echo=FALSE , warning=FALSE, message=FALSE}
#  R-squared difference
rsq(dtrain$aroma,dtrainP) - rsq(dtest$aroma,dtestP)
```

### Model Table  

```{r, echo=FALSE , warning=FALSE, message=FALSE}
summary(model1)

tab_model(
  model1, show.se = TRUE, show.std = TRUE, show.stat = TRUE,
  col.order = c("p", "stat", "est", "std.se", "se", "std.est"))
```
### Plot Residual 

```{r, echo=FALSE , warning=FALSE, message=FALSE}
par(mfrow = c(2, 2))  # Split the plotting panel into a 2 x 2 grid
plot(model1)

```


After fitting the model measure the R-squared difference between R-squared for Test data[0.5602801] and R-squared for Train data [0.6841152].
the R-squared difference [0.1238351] which is not that bad for the model.

## Flavor and Acidity - Aroma
Now lets try the Linear Regression Model on diffrent values.
Here I used flavor and acidity to predict aroma using Linear Regression.

```{r, echo=FALSE , warning=FALSE, message=FALSE}
# Fitting a model 
set.seed(136)
gp <- runif(nrow(TestCoffeeData))
dtrain <- subset(TestCoffeeData , gp >= 0.3)
dtest <- subset(TestCoffeeData , gp < 0.3)

model2 <- lm( aroma ~ flavor + acidity, data = dtrain)

  dtestP <- predict(model2, newdata = dtest)
  dtrainP <- predict(model2, newdata = dtrain)

```

```{r, echo=FALSE , warning=FALSE, message=FALSE}
# computing R-squared 
rsq <- function(y , f) { 1 - sum((y - f)^2) / sum((y - mean(y))^2 ) }
#rsq <- function (x, y) cor(x, y) ^ 2
rsq(dtest$aroma,dtestP)
rsq(dtrain$aroma,dtrainP)
```

```{r, echo=FALSE , warning=FALSE, message=FALSE}
#  R-squared difference
rsq(dtrain$aroma,dtrainP) - rsq(dtest$aroma,dtestP)
```
After fitting the model measure the R-squared difference between R-squared for Test data[0.5643478] and R-squared for Train data [0.6960335].
the R-squared difference [0.1316857] which is not that bad for the model.

So, We can say that we can use flavor and acidity to predict the aroma of coffee.

### Model Table

```{r, echo=FALSE , warning=FALSE, message=FALSE}
summary(model2)

tab_model(
  model2, show.se = TRUE, show.std = TRUE, show.stat = TRUE,
  col.order = c("p", "stat", "est", "std.se", "se", "std.est"))
```

### Plot Residual 

```{r, echo=FALSE , warning=FALSE, message=FALSE}
par(mfrow = c(2, 2))  # Split the plotting panel into a 2 x 2 grid
plot(model2)

```

